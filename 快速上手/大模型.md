
## Attention Is All You Need

https://mp.weixin.qq.com/s/RLxWevVWHXgX-UcoxDS70w

## 并行计算

* 横向切分（PP）：把模型不同层加载到不同显卡上，推理是串行的过程。
* 数据并行（DP）：数据分给不同显卡运算，充分利用多张显卡的算力。
* 纵向切分，张量并行（TP）：在DeepSpeed里叫模型并行（MP），模型进行纵向拆分。TP对GPU间通信要求最高，NVLINK通信速度可达600GB/s
* 3D并行：超大模型需要预训练，结合 DP+TP+PP 的模式。Colossal-AI的nD是针对张量并行，指的是TP的切分，对于矩阵各种切，和3D并行不是一回事。
* 可以使用更优化的数据并行算法FSDP（类似ZeRO3）或者直接使用DeepSpeed ZeRO。

## 扩散模型

### ControlNet

这个神经网络模型使得用户可以通过施加额外条件，细粒度地控制扩散模型的生成过程。作者开源了8个不同模型，可以用不同条件控制Stable Diffusion模型，包括姿态估计、深度图、边缘图、素描图 等等。

* https://huggingface.co/blog/zh/train-your-controlnet

### Diffusers

* 只需要几行代码，就能够利用扩散diffusion模型生成图像
* 可以使用不同的“噪声调节器”，来平衡模型生成速度和质量之间的关系
* 更有多种不同类型的模型，能够端到端的构建diffusion模型

### LoRA

LoRA，Low-Rank Adaptation of Large Language Models，大语言模型的低阶适应，微软为了解决大语言模型微调而开发。GPT-3有1750亿参数，如果直接对GPT-3做微调，成本太高太麻烦了。
LoRA的做法是，冻结预训练好的模型权重参数，然后在每个Transformer（Transformer就是GPT的那个T）块里注入可训练的层，由于不需要对模型的权重参数重新计算梯度，所以，大大减少了需要训练的计算量。LoRA的微调质量与全模型微调相当。

### DreamBooth

深度学习模型，用于微调现有文生图模型​（英语）。最初利用谷歌开发的的Imagen文生图模型开发，DreamBooth可以应用到其他文生图模型，在使用指定主题的三到五张图像进行演算、训练后，可以让模型产生更精细和个性化的输出图像。缓解SD无法生成特定个人图像的常见缺陷。

