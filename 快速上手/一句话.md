
# 数学

* 方差：衡量一组数据的波动程度，没有波动就是0。
* 基数：枚举值的数量，例如枚举值越多，基数越高。
* 归一化：把数值缩放到0-1之间。
* 线性回归：找出多个值之间的变化关系。
* 逻辑回归：多个值之间变化关系，得出0/1。
* 决策树：Decision Trees：通过多层判断，得出关系，可用于回归和分类
* 神经网络：多层进行非线性变化，每层需要有下一层的激活函数
* 全连接神经网络：Full Connected：每层都可以到下一层的所有值，需要很大的算力。
* 卷积神经网络：CNN：经过多次卷积和池化迭代。
  * 卷积层：Convolution：作为特征提取器，例如在图片中一个8x8的聚焦框，滑动到不同坐标再给下一层处理。
  * 池化层：Pooling：做采样，降低特征图的大小。
* 循环神经网络：RNN：输入跟上一时间的输入也有关。
* 长短期记忆：LSTM：Long Short-Term Memory：改善长时间错误的影响。

# 机器学习

* 过拟合：Overfitting：训练集表现很好，测试集不行，说明模型复杂度过高。较高方差。
* 欠拟合：训练集和测试集都不行。说明模型较高偏差。
* 学习率：Learning Rate：训练神经网络重要超参数之一，每次迭代中梯度向损失函数最优解移动的步长，通常η表示。决定学习速度快慢。在网络训练过程中，模型通过样本数据给出预测值，计算代价函数并通过反向传播来调整参数。
* 辍学率：Dropout Rate：通过在每次训练时，忽略一半的特征检测器，使模型更泛化，减少过拟合。
* 平坦层：Flatten layer：把输入压平，从多维变单维，常用在从卷积层到全链接层过渡。
* 卷积层：Convolutional layer：卷积神经网络中每层卷积层由若干卷积单元组成，每个卷积单元的参数都通过反向传播算法最佳化得到。卷积运算目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级特征如边缘、线条和角等层级，多层网路能从低级特征中迭代提取更复杂特征。
* 全链接层：Fully connected layers：FC：每个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。由于全相连，一般参数也最多。在卷积神经网络中起到“分类器”作用。
* 局部最小值：Local minimum：局部最优解。使用随机梯度下降，模拟退火等方法跳出局部最小值。
* 随机梯度下降：随机选择开始计算的点。
* 模拟退火：每步计算中以一定几率接受比当前更差的结果，保证算法稳定。
* 泛化能力：Generalization ability：算法对新样本的适应能力。
* 贝叶斯定理：事件概率和事件之间概率的关系。P(A|B)=P(B|A)*P(A)/P(B)。其中 P(A|B) 是条件概率，表示当事件B发生的情况下事件A发生的概率。贝叶斯定理中有先验概率和后验概率之分：
  * 先验概率：Prior Probability：根据以往经验和统计分析得到的概率。在“结果”发生前的概率，比如公式中的P(A)就是先验概率。先验概率一般作为“由因求果”问题中的“因”出现。
  * 后验概率：Posterior Probability：根据观察到的样本修正之后的概率值。在结果发生之后，我们根据“结果”来计算和分析最有可能导致该结果的原因，即“执果寻因”中的“因”。公式中的P(A|B)就是后验概率。
  * 患者病菌感染概率P(V)=5%，患者感冒概率P(C)=30%，患者因为病菌感染而感冒的概率P(C|V)=40%，那么得出感冒患者被病菌感染的后验概率P(V|C)=P(C|V)*P(V)/P(C)≈66.67%。
* 贝叶斯网络：Bayesian Network：描述随机变量（事件）之间关系的模型，基于贝叶斯定理对事物之间因果关系以及依赖关系进行量化，并使得因果或依赖关系的强弱可以被推理和计算。用有向无环图表示，节点代表随机变量，箭头表示节点间联系。如表示疾病和症状之间的概率关系。
* 泊松分布：Poisson Distribution：适合于描述单位时间内随机事件发生的次数。如：每小时走入商店人数，网络上每分钟丢包数。
* 均匀分布：Uniform distribution：一种简单的概率分布，分为离散型均匀分布和连续型均匀分布。
* 正态分布/高斯分布：Normal distribution/Gaussian distribution：概率密度函数曲线呈钟形。
* 二项分布：Binomial distribution：n个独立的成功/失败试验中成功的次数的离散概率分布，其中每次试验的成功概率为p。单次试验又称为伯努利试验。实际上，当n=1时，二项分布就是伯努利分布。
* 有向无环图：Directed Acyclic Graph：DAG：
* 常用CNN模型：
  * LeNet(1998) 手写体识别
  * AlexNet(2012)
  * VGG-16(2014)
  * ResNet(2015)
* CV 计算机视觉 常见问题
  * 分类：图片属于什么分类
  * 检测：对象在图中什么区域
  * 语义分割/图像分割：对象在图中的边界，绿幕换人

## 特征工程

* 特征缩放：特征归一化。
* 主成分分析/有效成分分析：Principal Component Analysis：PCA：特征降维方法，把存在一定相关关系的多个变量，变成尽可能少的新变量，使这些新变量两两不相关，减少变量数目。
* 高斯混合模型：GMM：只能用于连续特征。
* 多项式分布朴素贝叶斯模型：只能用于category特征。
* xgboost模型统一把特征按连续特征处理。建议还是用于连续特征，离散特征可以转one-hot，但是基数不要大于100。
* 离散特征建议用CatBoost 或 Light GBM。
* target encoding可以对离散特征转连续特征。

# 网络

* BFD：Bidirectional Forwarding Detection：双向转发侦测，用于侦测链路错误的网络协议，可用于链路高可用实时监测。
